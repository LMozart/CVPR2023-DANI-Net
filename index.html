<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>DANI-Net: Uncalibrated Photometric Stereo by Differentiable Shadow Handling, Anisotropic Reflectance Modeling, and Neural Inverse Rendering</title>
  <link rel="icon" type="image/x-icon" href="static/images/bunny.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


<section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">DANI-Net: Uncalibrated Photometric Stereo by Differentiable Shadow Handling, Anisotropic Reflectance Modeling, and Neural Inverse Rendering</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <!-- <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">First Author</a><sup>*</sup>,</span> -->
                <!-- Zongrui Li<sup>1</sup>,</span> -->
                <a href="https://github.com/LMozart" target="_blank">Zongrui Li</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="https://person.zju.edu.cn/zq" target="_blank">Qian Zheng</a><sup>2</sup>,</span>
                  <span class="author-block">
                    <a href="https://ci.idm.pku.edu.cn/" target="_blank">Boxin Shi</a><sup>3</sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://person.zju.edu.cn/en/gpan" target="_blank">Gang Pan</a><sup>2</sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://personal.ntu.edu.sg/exdjiang/" target="_blank">Xudong Jiang</a><sup>1</sup>,
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><font size="4"><sup>1</sup>Nanyang Technological University, <sup>2</sup>Zhejiang University, <sup>3</sup>Peking University</font> <br>CVPR 2023</span>
                    <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Li_DANI-Net_Uncalibrated_Photometric_Stereo_by_Differentiable_Shadow_Handling_Anisotropic_Reflectance_CVPR_2023_paper.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/LMozart/CVPR2023-DANI-Net" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2303.15101" 
                  target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Uncalibrated photometric stereo (UPS) is challenging due to the inherent ambiguity brought by the unknown light. Although the ambiguity is alleviated on non-Lambertian objects, the problem is still difficult to solve for more general objects with complex shapes introducing irregular shadows and general materials with complex reflectance like anisotropic reflectance. To exploit cues from shadow and reflectance to solve UPS and improve performance on general materials, we propose DANI-Net, an inverse rendering framework with differentiable shadow handling and anisotropic reflectance modeling. Unlike most previous methods that use non-differentiable shadow maps and assume isotropic material, our network benefits from cues of shadow and anisotropic reflectance through two differentiable paths. Experiments on multiple real-world datasets demonstrate our superior and robust performance.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- <section class="section hero is-light"> -->
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <p>
            The proposed DANI-Net differs from other PS or UPS methods in two aspects: 
            <ol>
              <li> <b>Shadow Handling</b>. The path in the sequence of inverse rendering errors, shadow maps, and surface normal maps (or light conditions) of the DANI-Net is differentiable; </li> 
              <li> <b>Reflectance Modeling</b>. DANI-Net adopts an anisotropic reflectance model. </li> 
            </ol>
            The proposed DANI-Net produces a smoother and more realistic shadow map, thanks to the differentiable shadow handling, and renders a more realistic image and Bidirectional Reflectance Distribution Function (BRDF) sphere (of the reference point) due to the anisotropic reflectance modeling.
          </p>
        </div>
           <img src="./static/images/teaser.png" alt="Teaser" style="width:60%;">
        </div>
        </div>
    </div>
  </div>
<!-- </section> -->
<br>
<br>
<br>

<!-- <section class="section hero is-light"> -->
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Soft Shadow Handling</h2>
        <div class="content has-text-justified">
          <p>
            DANI-Net implements a differentiable shadow handling method that fully exploits shadow cues to solve UPS. DANI-Net can generate realistic soft shaodw maps given arbitrary light directions.
          </p>
        </div>
          <img src="./static/images/shadow.gif" alt="Teaser" style="width:85%;">
          
      </div>
    </div>
  </div>
<!-- </section> -->

<br>
<br>
<br>


<!-- <section class="section hero is-light"> -->
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Anisotropic Reflectance Modeling</h2>
        <div class="content has-text-justified">
          <p>
            DANI-Net represents the spatially varying anisotropic specularity as a weighted sum of Anisotropic Spherical Gaussian (ASG). Thanks to ASG, DANI-Net can generate realistic appearance given arbitrary light conditions.
          </p>
        </div>
          <img src="./static/images/mat.gif" alt="Teaser" style="width:80%;">
      </div>
    </div>
  </div>
<!-- </section> -->

<br>
<br>
<br>

<div class="container is-max-desktop">
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h2 class="title is-3">Relighting</h2>
      <div class="content has-text-justified">
        <p>
          Given arbitrary directional lights, DANI-Net can relight the object with realistic appearance.
        </p>
      </div>
        <img src="./static/images/relighting.gif" alt="Teaser" style="width:85%;">
    </div>
  </div>
</div>
<br>
<br>
<br>

      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Video Presentation</h2>
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/4HSLZi7bfPA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
<br>
<br>
<br>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{li2023dani,
      title={DANI-Net: Uncalibrated Photometric Stereo by Differentiable Shadow Handling, Anisotropic Reflectance Modeling, and Neural Inverse Rendering},
      author={Li, Zongrui and Zheng, Qian and Shi, Boxin and Pan, Gang and Jiang, Xudong},
      booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
      year={2023}}
</code></pre>
  </div>
</section>

  </body>
  </html>
